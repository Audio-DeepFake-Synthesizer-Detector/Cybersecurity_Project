
@misc{GPAI,
  title = {GPAI Site},
  howpublished = {\url{https://gpai.ai/}}
}




@misc{OrigineDeepfake,
  title = {Origine Deepfake},
  howpublished = {\url{https://www.cybersecurity360.it/nuove-minacce/deepfake-in-tempo-reale-cosa-sono-come-funzionano-e-quali-tutele-per-prevenire-la-minaccia}}
}


@misc{LukeDeepfake,
  title = {Luke Deepfake},
  howpublished = {\url{https://www.gq-magazine.co.uk/culture/article/boba-fett-luke-skywalker}}
}

@misc{SuperareTrauma,
  title = {Superare un trauma},
  howpublished = {\url{https://www.wired.com/story/deepfake-death-grief-hologram-photography-film/}}
}


@misc{FakeVideoNancyPelosi,
  title = {Video fake di Nancy Pelosi},
  howpublished = {\url{https://www.washingtonpost.com/technology/2020/08/03/nancy-pelosi-fake-video-facebook/}}
}

@inproceedings {280020,
author = {Logan Blue and Kevin Warren and Hadi Abdullah and Cassidy Gibson and Luis Vargas and Jessica O{\textquoteright}Dell and Kevin Butler and Patrick Traynor},
title = {Who Are You (I Really Wanna Know)? Detecting Audio {DeepFakes} Through Vocal Tract Reconstruction},
booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
year = {2022},
isbn = {978-1-939133-31-1},
address = {Boston, MA},
pages = {2691--2708},
url = {https://www.usenix.org/conference/usenixsecurity22/presentation/blue},
publisher = {USENIX Association},
month = aug,
}


@article{DBLP:journals/corr/abs-1901-02212,
  author    = {Umur Aybars Ciftci and
               Ilke Demir},
  title     = {FakeCatcher: Detection of Synthetic Portrait Videos using Biological
               Signals},
  journal   = {CoRR},
  volume    = {abs/1901.02212},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.02212},
  eprinttype = {arXiv},
  eprint    = {1901.02212},
  timestamp = {Sat, 23 Jan 2021 01:19:44 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-02212.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{RealAudioDataset,
  title = {Real Audio Dataset},
  howpublished = {\url{https://commonvoice.mozilla.org/it/datasets}}
}

@misc{FakeAudioDataset,
  title = {Fake Audio Dataset},
  howpublished = {\url{https://www.asvspoof.org/index2021.html}}
}

@misc{bernaciak_2022, author="C. Bernaciak, and D. Ross",title="How Easy Is It to Make and Detect a Deepfake?", month="Mar. 14,",year="2022. [Online]",howpublished="Carnegie Mellon University's Software Engineering Institute Blog",url="http://insights.sei.cmu.edu/blog/how-easy-is-it-to-make-and-detect-a-deepfake/",note=Accessed:2022-Nov-28}

@article{KOBIS2021103364,
title = {Fooled twice: People cannot detect deepfakes but think they can},
journal = {iScience},
volume = {24},
number = {11},
pages = {103364},
year = {2021},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2021.103364},
url = {https://www.sciencedirect.com/science/article/pii/S2589004221013353},
author = {Nils C. Köbis and Barbora Doležalová and Ivan Soraperra},
keywords = {Neuroscience, Behavioral neuroscience, Cognitive neuroscience, Artificial intelligence, Artificial intelligence applications, Social sciences, Psychology},
abstract = {Summary
Hyper-realistic manipulations of audio-visual content, i.e., deepfakes, present new challenges for establishing the veracity of online content. Research on the human impact of deepfakes remains sparse. In a pre-registered behavioral experiment (N = 210), we show that (1) people cannot reliably detect deepfakes and (2) neither raising awareness nor introducing financial incentives improves their detection accuracy. Zeroing in on the underlying cognitive processes, we find that (3) people are biased toward mistaking deepfakes as authentic videos (rather than vice versa) and (4) they overestimate their own detection abilities. Together, these results suggest that people adopt a “seeing-is-believing” heuristic for deepfake detection while being overconfident in their (low) detection abilities. The combination renders people particularly susceptible to be influenced by deepfake content.}
}